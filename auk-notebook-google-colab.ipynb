{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auk-notebook-domains.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBblhps0lpYS",
        "colab_type": "text"
      },
      "source": [
        "# Welcome to AUK Notebook for Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF8nCdU7nbU9",
        "colab_type": "text"
      },
      "source": [
        "To leverage the GPU power offered by Google Colab, it would be useful to use Google Colab, a free Jupyter Notebook environment run on the Cloud, for Archive Unleashed. It would be particularly good for machine learning projects. In this notebook, we will look at different ways to access it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG9bNTeYlpYW",
        "colab_type": "text"
      },
      "source": [
        "## Using Google Colab with data from Github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaaJEYMjm2rB",
        "colab_type": "text"
      },
      "source": [
        "One simple way is to load the data from Github. There are some restrictions to this solution since Github restricts each file to 100MB and each repo to 1GB in size. \n",
        "\n",
        "Set up Google Colab to have the same environment as our github repo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBsgbRmmkvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/archivesunleashed/auk-notebooks.git\n",
        "!pip install -r auk-notebooks/requirements.txt\n",
        "!python -m nltk.downloader punkt vader_lexicon stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHoYuYda1Xwp",
        "colab_type": "text"
      },
      "source": [
        "The default directory is ~ which means you need to update AUK_PATH to 'auk-notebooks/data/'. To change that, you can do:\n",
        "\n",
        "```\n",
        "import sys\n",
        "sys.path.append(‘[desired path]’)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9j1Vfa-lpYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COLLECTION_ID = '4867'  # Change to switch collections.\n",
        "AUK_PATH = 'auk-notebooks/data/'  # Change value to full path to your data, including trailing slash."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA64zzUxnAJF",
        "colab_type": "text"
      },
      "source": [
        "## Using Google Colab with data from Google Cloud Storage (GCS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpTKidd_pQBG",
        "colab_type": "text"
      },
      "source": [
        "A personal account is allowed 5 GB of free storage per month (https://cloud.google.com/free/).\n",
        "\n",
        "First, you need to create a bucket in Google Cloud Platform and store the data there. Here are the steps you need to follow:\n",
        "\n",
        "\n",
        "1.   Create a Google Cloud Platform account (if you are already a Google user, you can simply use the same account).\n",
        "2.   Create a bucket (https://cloud.google.com/storage/docs/creating-buckets).\n",
        "3.   Update the bucket with the data. I simply loaded the files from https://github.com/archivesunleashed/auk-notebooks/tree/master/data\n",
        "4.   Authenticate yourself in Google Colab using the following snippet:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5nC-h9ZbEB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAwBl7sOqdGl",
        "colab_type": "text"
      },
      "source": [
        "You now have access to the *data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myi0ip8YwC2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bucket_name = 'archive_unleashed'\n",
        "file_path = '4867-fullurls.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jdtAbDXidxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9d74395c-78a8-4ee9-cb8c-f37f0215133c"
      },
      "source": [
        "# Option 1: You can load the data from GSC into a file\n",
        "!gsutil cp gs://{bucket_name}/{file_path} /tmp/example.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://archive_unleashed/4867-fullurls.txt...\n",
            "/ [0 files][    0.0 B/   13.0 B]                                                \r/ [1 files][   13.0 B/   13.0 B]                                                \r\n",
            "Operation completed over 1 objects/13.0 B.                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNw5WjNGh97y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Option 2: You can load the data from GSC to a blob\n",
        "from google.cloud import storage\n",
        "client = storage.Client(bucket_name)\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "blob = bucket.get_blob(file_name)\n",
        "print(blob.download_as_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuyKu62pk_d_",
        "colab_type": "text"
      },
      "source": [
        "The two solutions above require logging into a Google account that already have access to the files. If we want to provide access to a larger audience, it makes sense to use either an API key through Google IAM or offer full read permissions to the general public.\n",
        "\n",
        "1. use an API key through IAM. Unfortunately, I haven't found a good tutorial for this.\n",
        "2. Grant access to data to all users (using the snippet below) from the admin account. This is what I have done for my bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gba-J539IxzS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ad810cc0-6c1a-4cd6-b36f-ecf580a99af3"
      },
      "source": [
        "# !gsutil acl ch -u AllUsers:R gs://{bucket_name}/**"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated ACL on gs://archive_unleashed/4867-fulltext.txt\n",
            "Updated ACL on gs://archive_unleashed/4867-fullurls.txt\n",
            "Updated ACL on gs://archive_unleashed/4867-gephi.gexf\n",
            "Updated ACL on gs://archive_unleashed/4867-gephi.graphml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy8E7xHp6PmJ",
        "colab_type": "text"
      },
      "source": [
        "## Using Google Colab with data from AWS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbrBCCVAEczk",
        "colab_type": "text"
      },
      "source": [
        "It is also possible to store data onto the AWS Cloud platform. Using the free  tier of AWS, we have access to 5 GB/month of AWS S3 during the first 12 months of the account creation. Since S3 is a popular choice for cloud storing, we decided to try it out too.\n",
        "\n",
        "AWS Glacier is used as a write once, never retrieved cloud storage. It is a “extremely low-cost storage” that may be interesting to consider. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5Q01ZwiFqTX",
        "colab_type": "text"
      },
      "source": [
        "### Creating an AWS account\n",
        "\n",
        "I created a personal AWS account where I added a S3 bucket \"archiveunleashed\" and uploaded the \"data\" folder of this github repo unto the S3 bucket. I create a role \"archiveunleashed\" and retrieved its AWS access keys. Then, we need to connect the two together by defining a policy and inline policy which grants access to the bucket to this user.\n",
        "\n",
        "Creating and granting access to S3 is more difficult that Google Cloud, but there is a lot of tutorials available.\n",
        "\n",
        "\n",
        "Here is one: \n",
        "https://docs.aws.amazon.com/AmazonS3/latest/dev/example-walkthroughs-managing-access-example1.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXT4-cxr6QO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dc79fb83-13df-4855-96f1-e55622f02c60"
      },
      "source": [
        "import getpass\n",
        "\n",
        "aws_access_key_id = getpass.getpass(\"Enter AWS access key id: \")\n",
        "aws_secret_access_key = getpass.getpass(\"Enter AWS secret access key id: \")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter AWS access key id: ··········\n",
            "Enter AWS secret access key id: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGjvv5uztH6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bucket_name = 'archiveunleashed'\n",
        "remote_fname = '4867-fulltext.txt'\n",
        "local_fname = '/tmp/example.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn6PBUOaG3G-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import boto3\n",
        "\n",
        "s3r = boto3.resource(\n",
        "    's3', \n",
        "     aws_access_key_id=aws_access_key_id,\n",
        "     aws_secret_access_key=aws_secret_access_key\n",
        ")\n",
        "buck = s3r.Bucket(bucket_name)\n",
        "buck.download_file(remote_fname, local_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd1iPmB9FH3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat {local_fname}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HviCErbJse7k",
        "colab_type": "text"
      },
      "source": [
        "Additional links:\n",
        "\n",
        "1. Official documentation from Google Colab: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=L5cMl7XV65be\n",
        "2. Additional API from Google Cloud: https://colab.research.google.com/drive/1hPH7skySCZR-ZMJ6TmYLN1ug6vbq2cpb\n",
        "3. Free services from Google: https://cloud.google.com/free/\n",
        "4. Free services from AWS: https://aws.amazon.com/free/"
      ]
    }
  ]
}